#!/usr/bin/env python3
"""
ğŸ¯ YOLOv8 ëª¨ë¸ ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ
í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ê³  ì•„ë¦„ë‹¤ìš´ ì‹œê°í™” ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì •ëŸ‰ì  ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (mAP, Precision, Recall)
- ì‹œê°ì  ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì‹¬ì¸µ ë¶„ì„
- ì „ë¬¸ì ì¸ í‰ê°€ ë³´ê³ ì„œ ìƒì„±
"""

import cv2
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path
from ultralytics import YOLO
from collections import defaultdict, Counter
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import argparse
import yaml
import logging
import warnings
import koreanize_matplotlib

# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì • - ì „ë¬¸ì ì´ê³  ì•„ë¦„ë‹¤ìš´ ì°¨íŠ¸ë¥¼ ìœ„í•œ ê¸°ë³¸ ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
warnings.filterwarnings('ignore')

# ğŸ“Š ì‹œê°í™” ìƒìˆ˜ ì •ì˜ - ì¼ê´€ëœ ë””ìì¸ì„ ìœ„í•œ ìƒ‰ìƒê³¼ ìŠ¤íƒ€ì¼
class VisualConfig:
    """ì‹œê°í™” ì„¤ì •ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ - ê³¼ì‹¤ ê²€ì¶œì— ì í•©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒë“¤
    PRIMARY_COLORS = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']
    BACKGROUND_COLOR = '#F8F9FA'
    TEXT_COLOR = '#2C3E50'
    GRID_COLOR = '#E9ECEF'
    
    # í°íŠ¸ ì„¤ì •
    TITLE_FONT_SIZE = 16
    LABEL_FONT_SIZE = 12
    TICK_FONT_SIZE = 10
    
    # ì°¨íŠ¸ í¬ê¸° ì„¤ì •
    LARGE_FIGURE_SIZE = (16, 10)
    MEDIUM_FIGURE_SIZE = (12, 8)
    SMALL_FIGURE_SIZE = (10, 6)

def setup_logging(output_dir: Path, fruit_name: Optional[str] = None) -> logging.Logger:
    """
    ğŸ”§ í‰ê°€ ê³¼ì •ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •
    
    Args:
        output_dir: ë¡œê·¸ íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
        fruit_name: ê³¼ì‹¤ëª… (ë¡œê·¸ íŒŒì¼ëª…ì— í¬í•¨)
    
    Returns:
        ì„¤ì •ëœ ë¡œê±° ê°ì²´
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    
    fruit_suffix = f"_{fruit_name}" if fruit_name else ""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = output_dir / f"evaluation_{timestamp}{fruit_suffix}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"ğŸ¯ ëª¨ë¸ í‰ê°€ ì‹œì‘ - {fruit_name or 'ì¼ë°˜'} ëª¨ë“œ")
    return logger

def load_model_safely(model_path: Path) -> YOLO:
    """
    ğŸ¤– ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ ì¶œë ¥
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ë¡œë“œëœ YOLO ëª¨ë¸
        
    Raises:
        FileNotFoundError: ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
    """
    if not model_path.exists():
        raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
    
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path.name}")
    model = YOLO(str(model_path))
    
    # ëª¨ë¸ ê¸°ë³¸ ì •ë³´ ì¶œë ¥ - ì‚¬ìš©ìê°€ ì˜¬ë°”ë¥¸ ëª¨ë¸ì„ ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸
    try:
        model_info = model.info(verbose=False)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“ ëª¨ë¸ í¬ê¸°: {model_path.stat().st_size / (1024*1024):.1f}MB")
        print(f"   ğŸ·ï¸  í´ë˜ìŠ¤ ìˆ˜: {len(model.names)}ê°œ")
        print(f"   ğŸ“ í´ë˜ìŠ¤: {', '.join(list(model.names.values())[:5])}{'...' if len(model.names) > 5 else ''}")
    except:
        print(f"âš ï¸ ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì§€ë§Œ ë¡œë“œëŠ” ì„±ê³µí–ˆìŠµë‹ˆë‹¤.")
    
    return model

def calculate_comprehensive_metrics(model: YOLO, data_yaml_path: Path, 
                                  conf_threshold: float = 0.25, 
                                  iou_threshold: float = 0.45) -> Dict[str, Any]:
    """
    ğŸ“ˆ ì¢…í•©ì ì¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° - ë‹¨ìˆœí•œ ìˆ«ìë¥¼ ë„˜ì–´ ì˜ë¯¸ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ ì œê³µ
    
    Args:
        model: í‰ê°€í•  YOLO ëª¨ë¸
        data_yaml_path: ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼
        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        iou_threshold: IoU ì„ê³„ê°’
        
    Returns:
        ê³„ì‚°ëœ ëª¨ë“  ì„±ëŠ¥ ì§€í‘œë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    print("\nğŸ” === ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹œì‘ ===")
    
    # YOLO ë‚´ì¥ í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰ - ê°€ì¥ ì •í™•í•˜ê³  í‘œì¤€ì ì¸ ë°©ë²•
    results = model.val(
        data=str(data_yaml_path),
        split='test',
        conf=conf_threshold,
        iou=iou_threshold,
        verbose=False,  # ë¶ˆí•„ìš”í•œ ì¶œë ¥ ì–µì œ
        save_json=True   # ìƒì„¸ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    )
    
    # í•µì‹¬ ì§€í‘œ ì¶”ì¶œ ë° ì •ë¦¬
    metrics = {
        'overall': {
            'map50': float(results.box.map50),      # IoU 0.5ì—ì„œì˜ mAP
            'map50_95': float(results.box.map),     # IoU 0.5-0.95ì—ì„œì˜ mAP
            'precision': float(results.box.mp),     # ì „ì²´ ì •ë°€ë„
            'recall': float(results.box.mr),        # ì „ì²´ ì¬í˜„ìœ¨
            'f1_score': 2 * float(results.box.mp) * float(results.box.mr) / (float(results.box.mp) + float(results.box.mr)) if (float(results.box.mp) + float(results.box.mr)) > 0 else 0
        },
        'class_wise': {},
        'evaluation_settings': {
            'conf_threshold': conf_threshold,
            'iou_threshold': iou_threshold,
            'evaluation_time': datetime.now().isoformat()
        }
    }
    
    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ - ì–´ë–¤ ê³¼ì‹¤ì„ ê°€ì¥ ì˜/ëª» ì°¾ëŠ”ì§€ íŒŒì•…
    class_names = model.names
    if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:
        for idx, class_idx in enumerate(results.box.ap_class_index):
            if idx < len(results.box.ap50):
                class_name = class_names[class_idx]
                metrics['class_wise'][class_name] = {
                    'map50': float(results.box.ap50[idx]),
                    'class_id': int(class_idx)
                }
    
    # ì„±ëŠ¥ í‰ê°€ ì¶œë ¥ - ì‚¬ìš©ìê°€ í•œëˆˆì— ê²°ê³¼ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡
    print(f"ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½:")
    print(f"   ğŸ¯ mAP50: {metrics['overall']['map50']:.3f} ({'ìš°ìˆ˜' if metrics['overall']['map50'] > 0.7 else 'ì–‘í˜¸' if metrics['overall']['map50'] > 0.5 else 'ê°œì„ í•„ìš”'})")
    print(f"   ğŸ“ mAP50-95: {metrics['overall']['map50_95']:.3f}")
    print(f"   ğŸª ì •ë°€ë„: {metrics['overall']['precision']:.3f}")
    print(f"   ğŸ” ì¬í˜„ìœ¨: {metrics['overall']['recall']:.3f}")
    print(f"   âš–ï¸ F1-Score: {metrics['overall']['f1_score']:.3f}")
    
    if metrics['class_wise']:
        print(f"\nğŸ·ï¸ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (mAP50):")
        sorted_classes = sorted(metrics['class_wise'].items(), 
                              key=lambda x: x[1]['map50'], reverse=True)
        for class_name, class_metrics in sorted_classes:
            performance_emoji = "ğŸ†" if class_metrics['map50'] > 0.8 else "ğŸ¥ˆ" if class_metrics['map50'] > 0.6 else "ğŸ¥‰" if class_metrics['map50'] > 0.4 else "ğŸ“ˆ"
            print(f"   {performance_emoji} {class_name}: {class_metrics['map50']:.3f}")
    
    return metrics

def create_beautiful_visualizations(model: YOLO, test_images_dir: Path, 
                                  class_names: List[str], metrics: Dict[str, Any],
                                  output_dir: Path, num_samples: int = 20, 
                                  conf_threshold: float = 0.25) -> None:
    """
    ğŸ¨ ì „ë¬¸ì ì´ê³  ì•„ë¦„ë‹¤ìš´ ì‹œê°í™” ìƒì„± - ë…¼ë¬¸ì´ë‚˜ ë°œí‘œì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í’ˆì§ˆ
    
    Args:
        model: YOLO ëª¨ë¸
        test_images_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        metrics: ê³„ì‚°ëœ ì„±ëŠ¥ ì§€í‘œ
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        num_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ìˆ˜
        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
    """
    print(f"\nğŸ¨ === ì‹œê°í™” ìƒì„± ì‹œì‘ (ìƒ˜í”Œ {num_samples}ê°œ) ===")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘ - í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
    image_files = []
    
    # ì§€ì •ëœ ë””ë ‰í† ë¦¬ì™€ í•˜ìœ„ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘
    for ext in image_extensions:
        image_files.extend(list(test_images_dir.rglob(ext)))  # rglobìœ¼ë¡œ í•˜ìœ„ í´ë”ê¹Œì§€ ê²€ìƒ‰
    
    if not image_files:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_images_dir}")
        return
    
    print(f"ğŸ“ ì°¾ì€ ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    
    # ìƒ˜í”Œ ì´ë¯¸ì§€ ì„ íƒ - ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ê· ë“±í•˜ê²Œ ì„ íƒ
    selected_images = image_files[:num_samples] if len(image_files) >= num_samples else image_files
    
    # 1ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ ì‹œê°í™” - ì‹¤ì œ ê²€ì¶œ ê²°ê³¼ë¥¼ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤Œ
    _create_prediction_samples_visualization(model, selected_images, class_names, 
                                           conf_threshold, output_dir)
    
    # 2ï¸âƒ£ ì„±ëŠ¥ ì§€í‘œ ëŒ€ì‹œë³´ë“œ - í•œ ëˆˆì— ëª¨ë“  ì„±ëŠ¥ì„ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì¢…í•© ì°¨íŠ¸
    _create_performance_dashboard(metrics, class_names, output_dir)
    
    # 3ï¸âƒ£ ì‹ ë¢°ë„ ë¶„ì„ ì°¨íŠ¸ - ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ í™•ì‹ ì„ ê°€ì§€ê³  ì˜ˆì¸¡í•˜ëŠ”ì§€ ë¶„ì„
    _create_confidence_analysis(model, selected_images, class_names, 
                               conf_threshold, output_dir)

def _create_prediction_samples_visualization(model: YOLO, image_files: List[Path], 
                                           class_names: List[str], conf_threshold: float,
                                           output_dir: Path) -> None:
    """ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ ì‹œê°í™” - ì‹¤ì œ ê²€ì¶œ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬"""
    
    # ê²©ì ë ˆì´ì•„ì›ƒ ê³„ì‚° - ì´ë¯¸ì§€ ê°œìˆ˜ì— ë”°ë¼ ìµœì ì˜ ë°°ì¹˜ ê²°ì •
    n_images = min(len(image_files), 20)  # ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ í‘œì‹œ
    n_cols = 4
    n_rows = (n_images + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))
    fig.suptitle('ğŸ” ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ', fontsize=VisualConfig.TITLE_FONT_SIZE, 
                 fontweight='bold', y=0.98)
    
    # ë‹¨ì¼ ì´ë¯¸ì§€ì¸ ê²½ìš° axesë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if n_images == 1:
        axes = [axes]
    elif n_rows == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    
    for idx, image_path in enumerate(image_files[:n_images]):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì˜ˆì¸¡
            image = cv2.imread(str(image_path))
            if image is None:
                continue
                
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = model(image_path, conf=conf_threshold, verbose=False)
            
            # í˜„ì¬ subplot ì„¤ì •
            ax = axes[idx] if isinstance(axes, (list, np.ndarray)) else axes
            ax.imshow(image_rgb)
            ax.set_title(f"{image_path.stem}", fontsize=VisualConfig.LABEL_FONT_SIZE)
            ax.axis('off')
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            detection_count = 0
            if len(results) > 0 and results[0].boxes is not None:
                boxes = results[0].boxes
                
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf)
                    class_id = int(box.cls)
                    
                    if conf >= conf_threshold:
                        # í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ ì‚¬ìš©
                        color = VisualConfig.PRIMARY_COLORS[class_id % len(VisualConfig.PRIMARY_COLORS)]
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤
                        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                           linewidth=3, edgecolor=color,
                                           facecolor='none', alpha=0.8)
                        ax.add_patch(rect)
                        
                        # ë ˆì´ë¸” - ê°€ë…ì„±ì„ ìœ„í•œ ë°°ê²½ ì¶”ê°€
                        label = f"{class_names[class_id]} {conf:.2f}"
                        ax.text(x1, y1-10, label, 
                               color='white', fontweight='bold', fontsize=10,
                               bbox=dict(boxstyle="round,pad=0.3", 
                                       facecolor=color, alpha=0.8))
                        detection_count += 1
            
            # ê²€ì¶œ ê°œìˆ˜ í‘œì‹œ
            ax.text(0.02, 0.98, f"ê²€ì¶œ: {detection_count}ê°œ", 
                   transform=ax.transAxes, fontsize=10,
                   verticalalignment='top',
                   bbox=dict(boxstyle="round,pad=0.3", 
                           facecolor='white', alpha=0.7))
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {image_path.name} - {e}")
            continue
    
    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
    for idx in range(n_images, len(axes)):
        if isinstance(axes, (list, np.ndarray)) and idx < len(axes):
            axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'prediction_samples.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
    print(f"âœ… ì˜ˆì¸¡ ìƒ˜í”Œ ì €ì¥: prediction_samples.png")

def _create_performance_dashboard(metrics: Dict[str, Any], class_names: List[str], 
                                 output_dir: Path) -> None:
    """ì„±ëŠ¥ ì§€í‘œ ì¢…í•© ëŒ€ì‹œë³´ë“œ ìƒì„± - ì „ë¬¸ì ì¸ ë¶„ì„ ì°¨íŠ¸"""
    
    fig = plt.figure(figsize=VisualConfig.LARGE_FIGURE_SIZE)
    fig.suptitle('ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì¢…í•© ëŒ€ì‹œë³´ë“œ', fontsize=18, fontweight='bold')
    
    # 1. ì „ì²´ ì„±ëŠ¥ ì§€í‘œ ë°” ì°¨íŠ¸
    ax1 = plt.subplot(2, 3, 1)
    overall_metrics = metrics['overall']
    metric_names = ['mAP50', 'mAP50-95', 'Precision', 'Recall', 'F1-Score']
    metric_values = [overall_metrics['map50'], overall_metrics['map50_95'], 
                    overall_metrics['precision'], overall_metrics['recall'], 
                    overall_metrics['f1_score']]
    
    bars = ax1.bar(metric_names, metric_values, color=VisualConfig.PRIMARY_COLORS[:len(metric_names)],
                   alpha=0.8, edgecolor='white', linewidth=2)
    ax1.set_title('ì „ì²´ ì„±ëŠ¥ ì§€í‘œ', fontweight='bold')
    ax1.set_ylim(0, 1)
    ax1.grid(axis='y', alpha=0.3)
    
    # ê°’ ë ˆì´ë¸” ì¶”ê°€
    for bar, value in zip(bars, metric_values):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.xticks(rotation=45)
    
    # 2. í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¹„êµ (mAP50)
    if metrics['class_wise']:
        ax2 = plt.subplot(2, 3, 2)
        class_names_list = list(metrics['class_wise'].keys())
        class_scores = [metrics['class_wise'][name]['map50'] for name in class_names_list]
        
        bars = ax2.barh(class_names_list, class_scores, 
                       color=VisualConfig.PRIMARY_COLORS[:len(class_names_list)])
        ax2.set_title('í´ë˜ìŠ¤ë³„ mAP50', fontweight='bold')
        ax2.set_xlim(0, 1)
        ax2.grid(axis='x', alpha=0.3)
        
        # ê°’ ë ˆì´ë¸” ì¶”ê°€
        for bar, score in zip(bars, class_scores):
            ax2.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{score:.3f}', ha='left', va='center', fontweight='bold')
    
    # 3. ì„±ëŠ¥ ë“±ê¸‰ ë„ë„› ì°¨íŠ¸
    ax3 = plt.subplot(2, 3, 3)
    map50 = overall_metrics['map50']
    
    if map50 >= 0.8:
        grade, color = 'ìš°ìˆ˜', '#2ECC71'
    elif map50 >= 0.6:
        grade, color = 'ì–‘í˜¸', '#F39C12'
    elif map50 >= 0.4:
        grade, color = 'ë³´í†µ', '#E67E22'
    else:
        grade, color = 'ê°œì„ í•„ìš”', '#E74C3C'
    
    # ë„ë„› ì°¨íŠ¸ ìƒì„±
    wedges, texts = ax3.pie([map50, 1-map50], colors=[color, '#ECF0F1'], 
                           startangle=90, counterclock=False,
                           wedgeprops=dict(width=0.5))
    
    ax3.text(0, 0, f'{grade}\n{map50:.3f}', ha='center', va='center', 
            fontsize=14, fontweight='bold')
    ax3.set_title('ì„±ëŠ¥ ë“±ê¸‰', fontweight='bold')
    
    # 4-6. ì¶”ê°€ ë¶„ì„ ì°¨íŠ¸ë“¤ (ê³µê°„ í™œìš©)
    ax4 = plt.subplot(2, 3, (4, 6))
    
    # ì„±ëŠ¥ í•´ì„ ê°€ì´ë“œ í…ìŠ¤íŠ¸
    interpretation_text = f"""
ğŸ¯ ì„±ëŠ¥ í•´ì„ ê°€ì´ë“œ

mAP50: {overall_metrics['map50']:.3f} ({grade})
â€¢ 0.8 ì´ìƒ: ìƒìš©í™” ê°€ëŠ¥í•œ ìš°ìˆ˜í•œ ì„±ëŠ¥
â€¢ 0.6-0.8: ì‹¤ìš©ì  í™œìš© ê°€ëŠ¥í•œ ì–‘í˜¸í•œ ì„±ëŠ¥  
â€¢ 0.4-0.6: ê°œì„ ì„ í†µí•´ í™œìš© ê°€ëŠ¥í•œ ë³´í†µ ì„±ëŠ¥
â€¢ 0.4 ë¯¸ë§Œ: ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ì„±ëŠ¥

ê· í˜• ë¶„ì„:
â€¢ ì •ë°€ë„ vs ì¬í˜„ìœ¨: {overall_metrics['precision']:.3f} vs {overall_metrics['recall']:.3f}
â€¢ F1-Score: {overall_metrics['f1_score']:.3f}

ğŸ’¡ ê°œì„  ë°©í–¥:
â€¢ ì •ë°€ë„ê°€ ë‚®ìœ¼ë©´: False Positive ì¤„ì´ê¸° (ì„ê³„ê°’ ì¡°ì •)
â€¢ ì¬í˜„ìœ¨ì´ ë‚®ìœ¼ë©´: False Negative ì¤„ì´ê¸° (ë” ë§ì€ ë°ì´í„°)
â€¢ ë‘˜ ë‹¤ ë‚®ìœ¼ë©´: ëª¨ë¸ ìš©ëŸ‰ í™•ëŒ€ ë˜ëŠ” í•™ìŠµ ì‹œê°„ ì¦ê°€
"""
    
    ax4.text(0.05, 0.95, interpretation_text, transform=ax4.transAxes,
            fontsize=11, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor='#F8F9FA', alpha=0.8))
    ax4.axis('off')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'performance_dashboard.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
    print(f"âœ… ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì €ì¥: performance_dashboard.png")

def _create_confidence_analysis(model: YOLO, image_files: List[Path], 
                               class_names: List[str], conf_threshold: float,
                               output_dir: Path) -> None:
    """ì‹ ë¢°ë„ ë¶„ì„ ì°¨íŠ¸ ìƒì„± - ëª¨ë¸ì˜ í™•ì‹  ì •ë„ ë¶„ì„"""
    
    print("ğŸ” ì‹ ë¢°ë„ ë¶„ì„ ì¤‘...")
    
    # ëª¨ë“  ì˜ˆì¸¡ì—ì„œ ì‹ ë¢°ë„ ì •ë³´ ìˆ˜ì§‘
    all_confidences = []
    class_confidences = defaultdict(list)
    detection_counts = []
    
    for image_path in image_files[:50]:  # ì‹ ë¢°ë„ ë¶„ì„ì€ 50ê°œ ì´ë¯¸ì§€ë¡œ ì œí•œ
        try:
            results = model(image_path, conf=0.01, verbose=False)  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ëª¨ë“  ì˜ˆì¸¡ ìˆ˜ì§‘
            
            image_detections = 0
            if len(results) > 0 and results[0].boxes is not None:
                boxes = results[0].boxes
                
                for box in boxes:
                    conf = float(box.conf)
                    class_id = int(box.cls)
                    class_name = class_names[class_id] if class_id < len(class_names) else f"Class_{class_id}"
                    
                    all_confidences.append(conf)
                    class_confidences[class_name].append(conf)
                    
                    if conf >= conf_threshold:
                        image_detections += 1
            
            detection_counts.append(image_detections)
            
        except Exception as e:
            continue
    
    if not all_confidences:
        print("âš ï¸ ì‹ ë¢°ë„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return
    
    # ì‹ ë¢°ë„ ë¶„ì„ ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=VisualConfig.LARGE_FIGURE_SIZE)
    fig.suptitle('ğŸª ëª¨ë¸ ì‹ ë¢°ë„ ë¶„ì„', fontsize=16, fontweight='bold')
    
    # 1. ì „ì²´ ì‹ ë¢°ë„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
    ax1 = axes[0, 0]
    ax1.hist(all_confidences, bins=30, alpha=0.7, color=VisualConfig.PRIMARY_COLORS[0],
            edgecolor='white', linewidth=1)
    ax1.axvline(conf_threshold, color='red', linestyle='--', linewidth=2,
               label=f'ì„ê³„ê°’: {conf_threshold}')
    ax1.set_xlabel('ì‹ ë¢°ë„')
    ax1.set_ylabel('ë¹ˆë„')
    ax1.set_title('ì‹ ë¢°ë„ ë¶„í¬')
    ax1.legend()
    ax1.grid(alpha=0.3)
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    mean_conf = np.mean(all_confidences)
    ax1.text(0.7, 0.8, f'í‰ê· : {mean_conf:.3f}\ní‘œì¤€í¸ì°¨: {np.std(all_confidences):.3f}',
            transform=ax1.transAxes, bbox=dict(boxstyle="round,pad=0.3", 
                                              facecolor='white', alpha=0.8))
    
    # 2. í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ë°•ìŠ¤í”Œë¡¯
    ax2 = axes[0, 1]
    if class_confidences:
        class_data = []
        class_labels = []
        for class_name, confs in class_confidences.items():
            if len(confs) >= 5:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” í´ë˜ìŠ¤ë§Œ
                class_data.append(confs)
                class_labels.append(class_name)
        
        if class_data:
            bp = ax2.boxplot(class_data, labels=class_labels, patch_artist=True)
            
            # ë°•ìŠ¤í”Œë¡¯ ìƒ‰ìƒ ì„¤ì •
            for patch, color in zip(bp['boxes'], VisualConfig.PRIMARY_COLORS):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            ax2.set_ylabel('ì‹ ë¢°ë„')
            ax2.set_title('í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ë¶„í¬')
            ax2.tick_params(axis='x', rotation=45)
            ax2.grid(alpha=0.3)
    
    # 3. ì´ë¯¸ì§€ë‹¹ ê²€ì¶œ ê°œìˆ˜ ë¶„í¬
    ax3 = axes[1, 0]
    detection_counter = Counter(detection_counts)
    counts = sorted(detection_counter.keys())
    frequencies = [detection_counter[c] for c in counts]
    
    bars = ax3.bar(counts, frequencies, color=VisualConfig.PRIMARY_COLORS[2], alpha=0.7,
                  edgecolor='white', linewidth=1)
    ax3.set_xlabel('ì´ë¯¸ì§€ë‹¹ ê²€ì¶œ ê°œìˆ˜')
    ax3.set_ylabel('ì´ë¯¸ì§€ ìˆ˜')
    ax3.set_title('ê²€ì¶œ ê°œìˆ˜ ë¶„í¬')
    ax3.grid(alpha=0.3)
    
    # í‰ê·  ê²€ì¶œ ê°œìˆ˜ í‘œì‹œ
    mean_detections = np.mean(detection_counts)
    ax3.axvline(mean_detections, color='red', linestyle='--', linewidth=2,
               label=f'í‰ê· : {mean_detections:.1f}ê°œ')
    ax3.legend()
    
    # 4. ì‹ ë¢°ë„ ì„ê³„ê°’ë³„ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
    ax4 = axes[1, 1]
    thresholds = np.arange(0.1, 1.0, 0.05)
    detection_rates = []
    
    for threshold in thresholds:
        valid_detections = sum(1 for conf in all_confidences if conf >= threshold)
        detection_rate = valid_detections / len(all_confidences) if all_confidences else 0
        detection_rates.append(detection_rate)
    
    ax4.plot(thresholds, detection_rates, linewidth=3, color=VisualConfig.PRIMARY_COLORS[3],
            marker='o', markersize=4)
    ax4.axvline(conf_threshold, color='red', linestyle='--', linewidth=2,
               label=f'í˜„ì¬ ì„ê³„ê°’: {conf_threshold}')
    ax4.set_xlabel('ì‹ ë¢°ë„ ì„ê³„ê°’')
    ax4.set_ylabel('ê²€ì¶œ ë¹„ìœ¨')
    ax4.set_title('ì„ê³„ê°’ë³„ ê²€ì¶œ ë¹„ìœ¨')
    ax4.legend()
    ax4.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'confidence_analysis.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
    print(f"âœ… ì‹ ë¢°ë„ ë¶„ì„ ì €ì¥: confidence_analysis.png")

def generate_professional_report(model_path: Path, metrics: Dict[str, Any], 
                               data_config: Dict[str, Any], output_dir: Path,
                               fruit_name: Optional[str] = None) -> None:
    """
    ğŸ“‹ ì „ë¬¸ì ì¸ í‰ê°€ ë³´ê³ ì„œ ìƒì„± - ì—°êµ¬ë‚˜ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€
    
    Args:
        model_path: í‰ê°€ëœ ëª¨ë¸ ê²½ë¡œ
        metrics: ê³„ì‚°ëœ ì„±ëŠ¥ ì§€í‘œ
        data_config: ë°ì´í„°ì…‹ ì„¤ì • ì •ë³´
        output_dir: ë³´ê³ ì„œ ì €ì¥ ë””ë ‰í† ë¦¬
        fruit_name: ê³¼ì‹¤ëª… (ë³´ê³ ì„œ ì œëª©ì— í¬í•¨)
    """
    
    # ë³´ê³ ì„œ ë©”íƒ€ë°ì´í„°
    eval_time = datetime.now()
    fruit_title = f"{fruit_name} " if fruit_name else ""
    
    # ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°
    map50 = metrics['overall']['map50']
    if map50 >= 0.8:
        performance_grade = "ìš°ìˆ˜ (Excellent)"
        recommendation = "ìƒìš©í™” ì¤€ë¹„ ì™„ë£Œ"
    elif map50 >= 0.6:
        performance_grade = "ì–‘í˜¸ (Good)"
        recommendation = "ì‹¤ìš©ì  í™œìš© ê°€ëŠ¥"
    elif map50 >= 0.4:
        performance_grade = "ë³´í†µ (Fair)"
        recommendation = "ì¶”ê°€ ê°œì„  ê¶Œì¥"
    else:
        performance_grade = "ê°œì„ í•„ìš” (Needs Improvement)"
        recommendation = "ìƒë‹¹í•œ ê°œì„  í•„ìš”"
    
    # í´ë˜ìŠ¤ë³„ ë¶„ì„
    class_analysis = ""
    if metrics['class_wise']:
        sorted_classes = sorted(metrics['class_wise'].items(), 
                              key=lambda x: x[1]['map50'], reverse=True)
        
        best_class = sorted_classes[0]
        worst_class = sorted_classes[-1]
        
        class_analysis = f"""
### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„

**ìµœê³  ì„±ëŠ¥ í´ë˜ìŠ¤**: {best_class[0]} (mAP50: {best_class[1]['map50']:.3f})
**ê°œì„  í•„ìš” í´ë˜ìŠ¤**: {worst_class[0]} (mAP50: {worst_class[1]['map50']:.3f})

| í´ë˜ìŠ¤ | mAP50 | ì„±ëŠ¥ ë“±ê¸‰ |
|--------|-------|-----------|"""
        
        for class_name, class_metrics in sorted_classes:
            class_map = class_metrics['map50']
            if class_map >= 0.7:
                class_grade = "ìš°ìˆ˜"
            elif class_map >= 0.5:
                class_grade = "ì–‘í˜¸"
            elif class_map >= 0.3:
                class_grade = "ë³´í†µ"
            else:
                class_grade = "ê°œì„ í•„ìš”"
            
            class_analysis += f"\n| {class_name} | {class_map:.3f} | {class_grade} |"
    
    # ìƒì„¸ ë³´ê³ ì„œ ë‚´ìš©
    report_content = f"""# ğŸ¯ {fruit_title}YOLOv8 ê°ì²´ ê²€ì¶œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë³´ê³ ì„œ

**í‰ê°€ ì¼ì‹œ**: {eval_time.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}  
**ëª¨ë¸ íŒŒì¼**: `{model_path.name}`  
**ë°ì´í„°ì…‹**: `{data_config.get('path', 'Unknown')}`  
**í‰ê°€ì**: ìë™ í‰ê°€ ì‹œìŠ¤í…œ  

---

## ğŸ“Š ì„±ëŠ¥ ìš”ì•½

### ì „ì²´ ì„±ëŠ¥ ì§€í‘œ
- **mAP50**: {metrics['overall']['map50']:.4f}
- **mAP50-95**: {metrics['overall']['map50_95']:.4f}
- **ì •ë°€ë„ (Precision)**: {metrics['overall']['precision']:.4f}
- **ì¬í˜„ìœ¨ (Recall)**: {metrics['overall']['recall']:.4f}
- **F1-Score**: {metrics['overall']['f1_score']:.4f}

### ì¢…í•© í‰ê°€
**ì„±ëŠ¥ ë“±ê¸‰**: {performance_grade}  
**ê¶Œì¥ì‚¬í•­**: {recommendation}

---

## ğŸ” ìƒì„¸ ë¶„ì„

### ì„±ëŠ¥ ì§€í‘œ í•´ì„

**mAP50 ({metrics['overall']['map50']:.3f})**
- ì´ ê°’ì€ IoU ì„ê³„ê°’ 0.5ì—ì„œì˜ í‰ê·  ì •ë°€ë„ì…ë‹ˆë‹¤
- ê°’ì´ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ì°¾ê³  ë¶„ë¥˜í•˜ëŠ” ëŠ¥ë ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤
- 0.8 ì´ìƒì´ë©´ ìƒìš©í™” ê°€ëŠ¥í•œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì…ë‹ˆë‹¤

**ì •ë°€ë„ vs ì¬í˜„ìœ¨ ê· í˜•**
- ì •ë°€ë„ {metrics['overall']['precision']:.3f}: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œë¡œ ë§ëŠ” ë¹„ìœ¨
- ì¬í˜„ìœ¨ {metrics['overall']['recall']:.3f}: ì‹¤ì œ ê°ì²´ ì¤‘ ëª¨ë¸ì´ ì°¾ì•„ë‚¸ ë¹„ìœ¨
- F1-Score {metrics['overall']['f1_score']:.3f}: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· 

{class_analysis}

---

## ğŸ¯ ê°œì„  ë°©ì•ˆ

### ë‹¨ê¸° ê°œì„  (1-2ì£¼)
1. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
   - ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •: í˜„ì¬ {metrics['evaluation_settings']['conf_threshold']}
   - IoU ì„ê³„ê°’ ìµœì í™”: í˜„ì¬ {metrics['evaluation_settings']['iou_threshold']}
   - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ ì¡°ì •

2. **ë°ì´í„° ì¦ê°• ê°•í™”**
   - ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ ì¶”ê°€
   - íšŒì „, í¬ê¸° ë³€ê²½, ìƒ‰ìƒ ì¡°ì • ì ìš©
   - ë°°ê²½ ë‹¤ì–‘í™”

### ì¤‘ê¸° ê°œì„  (1-2ê°œì›”)
1. **ë°ì´í„°ì…‹ í™•ì¥**
   - ë¶€ì¡±í•œ í´ë˜ìŠ¤ì˜ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘
   - ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ (ê²¹ì¹¨, ë¶€ë¶„ ê°€ë¦¼) ë°ì´í„° ë³´ê°•
   - ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ë°ì´í„° ìˆ˜ì§‘

2. **ëª¨ë¸ êµ¬ì¡° ê°œì„ **
   - ë” í° YOLOv8 ëª¨ë¸ (s â†’ m â†’ l â†’ x) ì‹¤í—˜
   - ì•™ìƒë¸” ê¸°ë²• ì ìš©
   - ì»¤ìŠ¤í…€ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ ê²€í† 

### ì¥ê¸° ê°œì„  (3-6ê°œì›”)
1. **ë„ë©”ì¸ íŠ¹í™” ìµœì í™”**
   - ë†ì—…/ê³¼ì‹¤ íŠ¹í™” ì „ì²˜ë¦¬ ê¸°ë²• ê°œë°œ
   - ì‹œê°„ëŒ€ë³„, ê³„ì ˆë³„ ëª¨ë¸ ê°œë°œ
   - ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”

2. **ë°°í¬ í™˜ê²½ ìµœì í™”**
   - ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤ ìµœì í™”
   - í´ë¼ìš°ë“œ API ê°œë°œ
   - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“ˆ ì„±ëŠ¥ ê¸°ì¤€ ë° ë²¤ì¹˜ë§ˆí¬

| ì„±ëŠ¥ ë“±ê¸‰ | mAP50 ë²”ìœ„ | í™œìš© ê°€ëŠ¥ì„± | ê¶Œì¥ ì¡°ì¹˜ |
|-----------|------------|-------------|-----------|
| ìš°ìˆ˜ | 0.8 ì´ìƒ | ì¦‰ì‹œ ìƒìš©í™” ê°€ëŠ¥ | ìœ ì§€ë³´ìˆ˜ ë° ëª¨ë‹ˆí„°ë§ |
| ì–‘í˜¸ | 0.6 - 0.8 | ì‹¤ìš©ì  í™œìš© ê°€ëŠ¥ | ì†Œí­ ê°œì„  í›„ í™œìš© |
| ë³´í†µ | 0.4 - 0.6 | ì œí•œì  í™œìš© ê°€ëŠ¥ | ìƒë‹¹í•œ ê°œì„  í•„ìš” |
| ê°œì„ í•„ìš” | 0.4 ë¯¸ë§Œ | ì¶”ê°€ ê°œë°œ í•„ìš” | ì „ë©´ì  ì¬ê²€í†  |

---

## ğŸ”§ ê¸°ìˆ ì  ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ 
- ì‹ ë¢°ë„ ì„ê³„ê°’ì„ {max(0.1, metrics['evaluation_settings']['conf_threshold'] - 0.05):.2f}ë¡œ ë‚®ì¶°ì„œ ì¬í˜„ìœ¨ í–¥ìƒ ì‹œë„
- í…ŒìŠ¤íŠ¸ ì‹œê°„ ì¦ê°•(TTA) ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
- í›„ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”

### ë°ì´í„° ê´€ë ¨ ê¶Œì¥ì‚¬í•­
- í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ì¡°ì •
- í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë§ˆì´ë‹ ì ìš©
- í¬ë¡œìŠ¤ ê²€ì¦ì„ í†µí•œ ì•ˆì •ì„± í™•ì¸

---

## ğŸ“Š ë¶€ë¡: ìƒì„¸ í†µê³„

### í‰ê°€ í™˜ê²½
- **í‰ê°€ ì¼ì‹œ**: {eval_time.isoformat()}
- **ì‹ ë¢°ë„ ì„ê³„ê°’**: {metrics['evaluation_settings']['conf_threshold']}
- **IoU ì„ê³„ê°’**: {metrics['evaluation_settings']['iou_threshold']}
- **í´ë˜ìŠ¤ ìˆ˜**: {len(data_config.get('names', []))}

### ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìƒì„¸
```
ì „ì²´ ì„±ëŠ¥:
  mAP50    : {metrics['overall']['map50']:.6f}
  mAP50-95 : {metrics['overall']['map50_95']:.6f}
  Precision: {metrics['overall']['precision']:.6f}
  Recall   : {metrics['overall']['recall']:.6f}
  F1-Score : {metrics['overall']['f1_score']:.6f}
```

---

**ë³´ê³ ì„œ ìƒì„±**: ìë™ í‰ê°€ ì‹œìŠ¤í…œ v2.0  
**ë¬¸ì˜**: ëª¨ë¸ ê°œë°œíŒ€  
**ë‹¤ìŒ í‰ê°€ ì˜ˆì •**: ëª¨ë¸ ê°œì„  í›„ ì¬í‰ê°€ ê¶Œì¥
"""

    # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
    fruit_suffix = f"_{fruit_name}" if fruit_name else ""
    report_filename = f"evaluation_report{fruit_suffix}_{eval_time.strftime('%Y%m%d_%H%M%S')}.md"
    report_path = output_dir / report_filename
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    # CSV í˜•íƒœì˜ ìˆ˜ì¹˜ ë°ì´í„°ë„ ì €ì¥
    metrics_df = pd.DataFrame([
        {
            'metric': 'mAP50',
            'value': metrics['overall']['map50'],
            'category': 'overall'
        },
        {
            'metric': 'mAP50-95', 
            'value': metrics['overall']['map50_95'],
            'category': 'overall'
        },
        {
            'metric': 'Precision',
            'value': metrics['overall']['precision'], 
            'category': 'overall'
        },
        {
            'metric': 'Recall',
            'value': metrics['overall']['recall'],
            'category': 'overall'
        },
        {
            'metric': 'F1-Score',
            'value': metrics['overall']['f1_score'],
            'category': 'overall'
        }
    ])
    
    # í´ë˜ìŠ¤ë³„ ë°ì´í„° ì¶”ê°€
    for class_name, class_metrics in metrics.get('class_wise', {}).items():
        metrics_df = pd.concat([metrics_df, pd.DataFrame([{
            'metric': 'mAP50',
            'value': class_metrics['map50'],
            'category': class_name
        }])], ignore_index=True)
    
    csv_filename = f"evaluation_metrics{fruit_suffix}_{eval_time.strftime('%Y%m%d_%H%M%S')}.csv"
    metrics_df.to_csv(output_dir / csv_filename, index=False, encoding='utf-8')
    
    print(f"ğŸ“‹ í‰ê°€ ë³´ê³ ì„œ ì €ì¥: {report_filename}")
    print(f"ğŸ“Š ìˆ˜ì¹˜ ë°ì´í„° ì €ì¥: {csv_filename}")

def main():
    """ğŸš€ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì „ì²´ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì¡°ìœ¨"""
    
    parser = argparse.ArgumentParser(
        description='ğŸ¯ YOLOv8 ëª¨ë¸ ì¢…í•© ì„±ëŠ¥ í‰ê°€ ì‹œìŠ¤í…œ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python evaluate_model.py --model best.pt --data data.yaml
  python evaluate_model.py --model best_apple.pt --data data.yaml --fruit apple --samples 50
  python evaluate_model.py --model model.pt --data data.yaml --conf_threshold 0.3 --output_dir results
  python evaluate_model.py --model best.pt --data data.yaml --test_images_dir /path/to/test/images
        """
    )
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument('--model', required=True, help='í‰ê°€í•  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pt)')
    parser.add_argument('--data', required=True, help='ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ (data.yaml)')
    
    # ì„ íƒì  ì¸ì
    parser.add_argument('--output_dir', default='evaluation_results', 
                       help='í‰ê°€ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: evaluation_results)')
    parser.add_argument('--test_images_dir', type=str,
                       help='í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ data.yamlì˜ ê²½ë¡œ ì‚¬ìš©)')
    parser.add_argument('--fruit', type=str, 
                       help='ê³¼ì‹¤ëª… (ê²°ê³¼ íŒŒì¼ëª…ì— í¬í•¨, ì„ íƒì‚¬í•­)')
    parser.add_argument('--conf_threshold', type=float, default=0.25,
                       help='ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.25)')
    parser.add_argument('--iou_threshold', type=float, default=0.45,
                       help='IoU ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.45)')
    parser.add_argument('--samples', type=int, default=20,
                       help='ì‹œê°í™”í•  ìƒ˜í”Œ ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 20)')
    
    args = parser.parse_args()
    
    # ê²½ë¡œ ì„¤ì •
    model_path = Path(args.model)
    data_yaml_path = Path(args.data)
    output_dir = Path(args.output_dir)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    logger = setup_logging(output_dir, args.fruit)
    
    try:
        print(f"\nğŸ¯ === YOLOv8 ëª¨ë¸ ì¢…í•© í‰ê°€ ì‹œì‘ ===")
        print(f"ğŸ“ ëª¨ë¸: {model_path}")
        print(f"ğŸ“Š ë°ì´í„°: {data_yaml_path}")
        print(f"ğŸ’¾ ê²°ê³¼: {output_dir}")
        if args.fruit:
            print(f"ğŸ ê³¼ì‹¤: {args.fruit}")
        
        # 1ï¸âƒ£ ëª¨ë¸ ë¡œë“œ
        model = load_model_safely(model_path)
        
        # 2ï¸âƒ£ ë°ì´í„° ì„¤ì • ë¡œë“œ
        if not data_yaml_path.exists():
            raise FileNotFoundError(f"âŒ ë°ì´í„° ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_yaml_path}")
        
        with open(data_yaml_path, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)
        
        class_names = data_config.get('names', [])
        if not class_names:
            raise ValueError("âŒ ë°ì´í„° ì„¤ì •ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 3ï¸âƒ£ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = calculate_comprehensive_metrics(
            model, data_yaml_path, args.conf_threshold, args.iou_threshold
        )
        
        # 4ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì •
        if args.test_images_dir:
            # ì‚¬ìš©ìê°€ ì§€ì •í•œ ê²½ë¡œ ì‚¬ìš©
            test_images_dir = Path(args.test_images_dir)
            print(f"ğŸ–¼ï¸ ì‚¬ìš©ì ì§€ì • í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ: {test_images_dir}")
        else:
            # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (data.yaml ê¸°ì¤€)
            test_images_dir = Path(data_config['path']) / 'images' / 'test'
            print(f"ğŸ–¼ï¸ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ: {test_images_dir}")
        
        # 5ï¸âƒ£ ì‹œê°í™” ìƒì„±
        if test_images_dir.exists():
            create_beautiful_visualizations(
                model, test_images_dir, class_names, metrics, 
                output_dir, args.samples, args.conf_threshold
            )
        else:
            logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_images_dir}")
            print(f"âš ï¸ ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print(f"   - ì§€ì •ëœ ê²½ë¡œ: {test_images_dir}")
            if args.test_images_dir:
                default_path = Path(data_config['path']) / 'images' / 'test'
                print(f"   - ê¸°ë³¸ ê²½ë¡œ: {default_path}")
        
        # 6ï¸âƒ£ ì „ë¬¸ ë³´ê³ ì„œ ìƒì„±
        generate_professional_report(
            model_path, metrics, data_config, output_dir, args.fruit
        )
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ‰ === í‰ê°€ ì™„ë£Œ ===")
        print(f"ğŸ“Š ì „ì²´ ì„±ëŠ¥ (mAP50): {metrics['overall']['map50']:.3f}")
        print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_dir}")
        print(f"ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”!")
        
        logger.info(f"í‰ê°€ ì™„ë£Œ - mAP50: {metrics['overall']['map50']:.3f}")
        
    except Exception as e:
        error_msg = f"ğŸ’¥ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        print(error_msg)
        logger.error(error_msg)
        raise

if __name__ == "__main__":
    main()