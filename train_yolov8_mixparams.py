#!/usr/bin/env python3
"""
YOLOv8 ê³¼ì‹¤ Detection ëª¨ë¸ í•™ìŠµ (Detection ìœ íš¨ ì¸ìë§Œ)
- ë‚´ì¥ ì¦ê°•: mosaic, mixup, copy_paste, hsv_h/s/v, fliplr/flipud,
             degrees/translate/scale/shear/perspective
- ê¸°íƒ€: close_mosaic, freeze, cos_lr ë“±
- ì§ê´€ì ì¸ ë””ë ‰í† ë¦¬ëª…ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
- ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ì  ê¸°ëŠ¥: train ì›ë³¸ 3ì¥ + ê° ë‹¨ê³„ ê²°ê³¼ ì €ì¥
- ìˆ˜ì •: í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ êµ¬ë¶„ bboxë§Œ í‘œì‹œ (í…ìŠ¤íŠ¸ ì œê±°)
"""

import os
import yaml
import torch
import random
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import argparse
import logging
from datetime import datetime
import shutil
from PIL import Image, ImageDraw, ImageFont

def setup_logging(log_dir, fruit_name=None):
    log_dir = Path(log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)
    fruit_suffix = f"_{fruit_name}" if fruit_name else ""
    log_file = log_dir / f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}{fruit_suffix}.log"
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.FileHandler(log_file), logging.StreamHandler()]
    )
    logger = logging.getLogger(__name__)
    if fruit_name:
        logger.info(f"ğŸ ê³¼ì‹¤ ì¢…ë¥˜: {fruit_name}")
    return logger

def verify_gpu_availability():
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_device)
        print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_count}ê°œ GPU ê°ì§€")
        print(f"í˜„ì¬ GPU: {gpu_name}")
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        total_memory = torch.cuda.get_device_properties(current_device).total_memory
        print(f"GPU ë©”ëª¨ë¦¬: {total_memory / 1024**3:.1f}GB")
        return True
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í•™ìŠµí•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.")
        return False

def load_and_verify_config(data_yaml_path):
    data_yaml_path = Path(data_yaml_path)
    if not data_yaml_path.exists():
        raise FileNotFoundError(f"data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_yaml_path}")
    with open(data_yaml_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    required_keys = ['path', 'train', 'val', 'nc', 'names']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"data.yamlì— í•„ìˆ˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {key}")
    base_path = Path(config['path'])
    for split in ['train', 'val']:
        if split in config:
            split_path = base_path / config[split]
            if not split_path.exists():
                raise FileNotFoundError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {split_path}")
    if len(config['names']) != config['nc']:
        raise ValueError(f"í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜: nc={config['nc']}, names ê¸¸ì´={len(config['names'])}")
    print("âœ… ë°ì´í„° ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    print(f"   - í´ë˜ìŠ¤ ìˆ˜: {config['nc']}")
    print(f"   - í´ë˜ìŠ¤: {config['names']}")
    print(f"   - ë°ì´í„° ê²½ë¡œ: {config['path']}")
    return config

def select_sample_images(data_config, num_samples=3):
    """train í´ë”ì—ì„œ ëœë¤í•˜ê²Œ ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì„ ì„ íƒ"""
    logger = logging.getLogger(__name__)
    base_path = Path(data_config['path'])
    train_images_path = base_path / data_config['train'] / 'images'
    if not train_images_path.exists():
        train_images_path = base_path / data_config['train']
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']
    all_images = []
    for ext in image_extensions:
        all_images.extend(list(train_images_path.glob(f'*{ext}')))
        all_images.extend(list(train_images_path.glob(f'*{ext.upper()}')))
    if len(all_images) < num_samples:
        logger.warning(f"train í´ë”ì— ì´ë¯¸ì§€ê°€ {len(all_images)}ì¥ ë°–ì— ì—†ì–´ì„œ ëª¨ë‘ ì„ íƒí•©ë‹ˆë‹¤.")
        num_samples = len(all_images)
    selected_images = random.sample(all_images, num_samples) if all_images else []
    logger.info(f"ğŸ“¸ ìƒ˜í”Œ ì´ë¯¸ì§€ {len(selected_images)}ì¥ ì„ íƒ:")
    for i, img_path in enumerate(selected_images, 1):
        logger.info(f"   {i}. {img_path.name}")
    return selected_images

def save_sample_original_images(selected_images, run_dir):
    """ì„ íƒëœ ì›ë³¸ ì´ë¯¸ì§€ë“¤ì„ samples í´ë”ì— ì €ì¥"""
    logger = logging.getLogger(__name__)
    samples_dir = run_dir / 'samples'
    original_dir = samples_dir / '01_original'
    original_dir.mkdir(parents=True, exist_ok=True)
    saved_paths = []
    for i, img_path in enumerate(selected_images, 1):
        dest_path = original_dir / f"sample_{i:02d}_{img_path.name}"
        shutil.copy2(img_path, dest_path)
        saved_paths.append(dest_path)
        logger.info(f"   ì›ë³¸ ì €ì¥: {dest_path.name}")
    return saved_paths

def create_augmented_samples(selected_images, run_dir, config):
    """ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ augmentation ì˜ˆì‹œ ìƒì„±"""
    logger = logging.getLogger(__name__)
    samples_dir = run_dir / 'samples'
    aug_dir = samples_dir / '02_augmented'
    aug_dir.mkdir(parents=True, exist_ok=True)
    try:
        # ê°„ë‹¨í•œ ì „ì²˜ë¦¬(ë¦¬ì‚¬ì´ì¦ˆ+íŒ¨ë”©)ë§Œ ì˜ˆì‹œë¡œ ì €ì¥
        for i, img_path in enumerate(selected_images, 1):
            try:
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                height, width = img.shape[:2]
                target_size = config['imgsz']
                scale = min(target_size/width, target_size/height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                resized_img = cv2.resize(img, (new_width, new_height))
                pad_width = (target_size - new_width) // 2
                pad_height = (target_size - new_height) // 2
                padded_img = cv2.copyMakeBorder(
                    resized_img, pad_height, target_size-new_height-pad_height,
                    pad_width, target_size-new_width-pad_width,
                    cv2.BORDER_CONSTANT, value=(114, 114, 114)
                )
                dest_path = aug_dir / f"sample_{i:02d}_preprocessed.jpg"
                cv2.imwrite(str(dest_path), padded_img)
            except Exception as e:
                logger.warning(f"ìƒ˜í”Œ {i} ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        logger.info(f"ğŸ“¸ ì „ì²˜ë¦¬ëœ ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {aug_dir}")
    except Exception as e:
        logger.warning(f"Augmentation ìƒ˜í”Œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

def get_class_color(class_id):
    """í´ë˜ìŠ¤ IDì— ë”°ë¥¸ ìƒ‰ìƒ ë°˜í™˜ (BGR í˜•ì‹)"""
    colors = {
        0: (0, 0, 255),    # ripened - ë¹¨ê°„ìƒ‰
        1: (0, 255, 0),    # ripening - ì—°ë‘ìƒ‰
        2: (255, 0, 0),    # unripened - íŒŒë€ìƒ‰
    }
    return colors.get(class_id, (128, 128, 128))  # ê¸°ë³¸ê°’: íšŒìƒ‰

def create_validation_predictions(selected_images, model, run_dir, data_config):
    """ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ validation ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± - í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ bboxë§Œ"""
    logger = logging.getLogger(__name__)
    samples_dir = run_dir / 'samples'
    val_dir = samples_dir / '03_validation'
    val_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        for i, img_path in enumerate(selected_images, 1):
            try:
                results = model(str(img_path), verbose=False)
                result = results[0]
                
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                # bbox ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ ì—†ì´, í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ)
                if result.boxes is not None:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        cls = int(box.cls[0].cpu().numpy())
                        
                        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸°
                        color = get_class_color(cls)
                        
                        # bboxë§Œ ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ ì œê±°)
                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                
                dest_path = val_dir / f"sample_{i:02d}_validation.jpg"
                cv2.imwrite(str(dest_path), img)
                
            except Exception as e:
                logger.warning(f"ìƒ˜í”Œ {i} validation ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
        logger.info(f"ğŸ“¸ Validation ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {val_dir}")
        logger.info("   ìƒ‰ìƒ êµ¬ë¶„: ë¹¨ê°•(ripened), ì—°ë‘(ripening), íŒŒë‘(unripened)")
        
    except Exception as e:
        logger.warning(f"Validation ì˜ˆì¸¡ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

def create_test_predictions(model, run_dir, data_config, num_samples=3):
    """í…ŒìŠ¤íŠ¸ìš© ëœë¤ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± - í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ bboxë§Œ"""
    logger = logging.getLogger(__name__)
    samples_dir = run_dir / 'samples'
    test_dir = samples_dir / '04_test_results'
    test_dir.mkdir(parents=True, exist_ok=True)
    
    base_path = Path(data_config['path'])
    val_images_path = base_path / data_config['val'] / 'images'
    if not val_images_path.exists():
        val_images_path = base_path / data_config['val']
    
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']
    all_images = []
    for ext in image_extensions:
        all_images.extend(list(val_images_path.glob(f'*{ext}')))
        all_images.extend(list(val_images_path.glob(f'*{ext.upper()}')))
    
    if len(all_images) == 0:
        logger.warning("í…ŒìŠ¤íŠ¸í•  validation ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    test_samples = min(num_samples, len(all_images))
    selected_test_images = random.sample(all_images, test_samples)
    
    try:
        for i, img_path in enumerate(selected_test_images, 1):
            try:
                results = model(str(img_path), verbose=False)
                result = results[0]
                
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                # bbox ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ ì—†ì´, í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ)
                if result.boxes is not None:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        cls = int(box.cls[0].cpu().numpy())
                        
                        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸°
                        color = get_class_color(cls)
                        
                        # bboxë§Œ ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ ì œê±°)
                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                
                dest_path = test_dir / f"test_{i:02d}_{img_path.name}"
                cv2.imwrite(str(dest_path), img)
                
            except Exception as e:
                logger.warning(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ {i} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
        logger.info(f"ğŸ“¸ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {test_dir}")
        logger.info("   ìƒ‰ìƒ êµ¬ë¶„: ë¹¨ê°•(ripened), ì—°ë‘(ripening), íŒŒë‘(unripened)")
        
    except Exception as e:
        logger.warning(f"í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

def create_sample_summary(run_dir, selected_images):
    """ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ìš”ì•½ ì •ë³´ ìƒì„±"""
    logger = logging.getLogger(__name__)
    samples_dir = run_dir / 'samples'
    summary_file = samples_dir / 'sample_summary.txt'
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("=== ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ì  ê²°ê³¼ ===\n\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("ì„ íƒëœ ì›ë³¸ ì´ë¯¸ì§€ë“¤:\n")
        for i, img_path in enumerate(selected_images, 1):
            f.write(f"{i}. {img_path.name}\n")
        f.write("\ní´ë” êµ¬ì¡°:\n")
        f.write("â”œâ”€â”€ 01_original/     - ì„ íƒëœ ì›ë³¸ ì´ë¯¸ì§€ë“¤\n")
        f.write("â”œâ”€â”€ 02_augmented/    - ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤\n")
        f.write("â”œâ”€â”€ 03_validation/   - í•™ìŠµëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼\n")
        f.write("â”œâ”€â”€ 04_test_results/ - í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼\n")
        f.write("â””â”€â”€ sample_summary.txt - ì´ íŒŒì¼\n\n")
        f.write("í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ êµ¬ë¶„:\n")
        f.write("- 0 (ripened): ë¹¨ê°„ìƒ‰\n")
        f.write("- 1 (ripening): ì—°ë‘ìƒ‰\n")
        f.write("- 2 (unripened): íŒŒë€ìƒ‰\n")
    logger.info(f"ğŸ“„ ìƒ˜í”Œ ìš”ì•½ ì •ë³´ ì €ì¥: {summary_file}")

def create_training_config(
    model_size='s',
    epochs=10,
    batch_size=32,
    imgsz=1080,
    optimizer='SGD',
    # ---- Detectionì—ì„œ ìœ íš¨í•œ Augmentations ----
    mosaic=1.0,
    mixup=0.7,
    copy_paste=0.5,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    fliplr=0.5,
    flipud=0.0,
    degrees=0.0,
    translate=0.1,
    scale=0.5,
    shear=0.0,
    perspective=0.0,
    close_mosaic=10,   # ë§ˆì§€ë§‰ N epochì—ì„œ mosaic ë„ê¸°
    # ---- Optim/Loss ----
    lr0=0.01,
    lrf=0.01,
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3,
    warmup_momentum=0.8,
    warmup_bias_lr=0.1,
    box_gain=7.5,
    cls_gain=0.5,
    dfl_gain=1.5,
    # ---- ê¸°íƒ€ ----
    freeze=0,          # 0ì´ë©´ ë™ê²° ì—†ìŒ. ì •ìˆ˜ë©´ ì•ìª½ n ë ˆì´ì–´ ë™ê²°
    cos_lr=False,      # ì½”ì‚¬ì¸ LR ìŠ¤ì¼€ì¤„ ì‚¬ìš© ì—¬ë¶€
    save_period=-1,
    workers=8,
    device=None,       # â† ì¶”ê°€: Noneì´ë©´ í‚¤ë¥¼ ë„£ì§€ ì•ŠìŒ
    **kwargs
):
    config = {
        'model': f'yolov8{model_size}.pt',
        'epochs': epochs,
        'batch': batch_size,
        'imgsz': imgsz,
        'optimizer': optimizer,
        'lr0': lr0,
        'lrf': lrf,
        'momentum': momentum,
        'weight_decay': weight_decay,
        'warmup_epochs': warmup_epochs,
        'warmup_momentum': warmup_momentum,
        'warmup_bias_lr': warmup_bias_lr,
        'box': box_gain,
        'cls': cls_gain,
        'dfl': dfl_gain,

        # ---- Detection Augs ----
        'mosaic': mosaic,
        'mixup': mixup,
        'copy_paste': copy_paste,
        'hsv_h': hsv_h,
        'hsv_s': hsv_s,
        'hsv_v': hsv_v,
        'fliplr': fliplr,
        'flipud': flipud,
        'degrees': degrees,
        'translate': translate,
        'scale': scale,
        'shear': shear,
        'perspective': perspective,
        'close_mosaic': close_mosaic,

        # ---- ê¸°íƒ€ ----
        'freeze': freeze,
        'cos_lr': cos_lr,

        'workers': workers,
        'save': True,
        'save_period': save_period,
        'val': True,
        'verbose': True,
        'seed': 42,
        'exist_ok': True,
    }
    # device ì§€ì • ì‹œì—ë§Œ í‚¤ ì¶”ê°€ (Ultralytics ê¸°ë³¸ ë™ì‘ ìœ ì§€)
    if device is not None:
        config['device'] = device
    config.update(kwargs)
    return config

def generate_descriptive_run_name(config, fruit_name=None):
    """ì§ê´€ì ì¸ ë””ë ‰í† ë¦¬ëª… ìƒì„± - ì£¼ìš” íŒŒë¼ë¯¸í„°ë§Œ í¬í•¨"""
    parts = []
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    parts.append(f"train_{timestamp}")
    if fruit_name:
        parts.append(f"fruit_{fruit_name}")
    model_name = config['model'].replace('yolov8', '').replace('.pt', '')
    parts.append(f"model_{model_name}")
    parts.append(f"ep{config['epochs']}")
    parts.append(f"bs{config['batch']}")
    parts.append(f"lr{config['lr0']}")
    parts.append(f"opt{config['optimizer']}")
    if config['imgsz'] != 640:
        parts.append(f"img{config['imgsz']}")
    aug_params = []
    if config['mixup'] != 0.0:
        aug_params.append(f"mixup{config['mixup']}")
    if config['mosaic'] != 1.0:
        aug_params.append(f"mosaic{config['mosaic']}")
    if config['flipud'] != 0.0:
        aug_params.append(f"flipud{config['flipud']}")
    if config['fliplr'] != 0.5:
        aug_params.append(f"fliplr{config['fliplr']}")
    if config['degrees'] != 0.0:
        aug_params.append(f"deg{config['degrees']}")
    if config['scale'] != 0.5:
        aug_params.append(f"scale{config['scale']}")
    if config['shear'] != 0.0:
        aug_params.append(f"shear{config['shear']}")
    if config['copy_paste'] != 0.0:
        aug_params.append(f"cp{config['copy_paste']}")
    if config['hsv_h'] != 0.015:
        aug_params.append(f"hsvh{config['hsv_h']}")
    if config['hsv_s'] != 0.7:
        aug_params.append(f"hsvs{config['hsv_s']}")
    if config['hsv_v'] != 0.4:
        aug_params.append(f"hsvv{config['hsv_v']}")
    if aug_params:
        parts.extend(aug_params)
    if config['cos_lr']:
        parts.append("cosLR")
    if config['freeze'] > 0:
        parts.append(f"freeze{config['freeze']}")
    return "_".join(parts)

def train_yolov8(data_yaml_path, output_dir, config, fruit_name=None):
    logger = logging.getLogger(__name__)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    data_config = load_and_verify_config(data_yaml_path)
    run_name = generate_descriptive_run_name(config, fruit_name)
    run_dir = output_dir / run_name
    logger.info(f"í•™ìŠµ ì‹œì‘: {run_name}")
    logger.info(f"ì¶œë ¥ ê²½ë¡œ: {run_dir}")
    try:
        logger.info("ğŸ¯ ìƒ˜í”Œ ì´ë¯¸ì§€ ì„ íƒ ì¤‘...")
        selected_images = select_sample_images(data_config, num_samples=3)
        save_sample_original_images(selected_images, run_dir)
        logger.info("ğŸ”„ ì „ì²˜ë¦¬ ìƒ˜í”Œ ìƒì„± ì¤‘...")
        create_augmented_samples(selected_images, run_dir, config)
        model_name = config['model']
        logger.info(f"ëª¨ë¸ ë¡œë“œ: {model_name}")
        model = YOLO(model_name)
        logger.info("ëª¨ë¸ êµ¬ì¡°:")
        logger.info(f"  - Parameters: {sum(p.numel() for p in model.model.parameters()):,}")
        logger.info(f"  - Trainable params: {sum(p.numel() for p in model.model.parameters() if p.requires_grad):,}")
        config_filename = f"training_config.yaml"
        config_save_path = run_dir / config_filename
        run_dir.mkdir(parents=True, exist_ok=True)
        config_to_save = config.copy()
        if fruit_name:
            config_to_save['fruit_name'] = fruit_name
        config_to_save['run_name'] = run_name
        config_to_save['selected_sample_images'] = [str(img) for img in selected_images]
        with open(config_save_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_to_save, f, default_flow_style=False, allow_unicode=True)
        logger.info(f"í•™ìŠµ ì„¤ì • ì €ì¥: {config_save_path}")
        logger.info("ğŸš€ í•™ìŠµ ì‹¤í–‰ ì¤‘...")
        results = model.train(
            data=data_yaml_path,
            project=str(output_dir),
            name=run_name,
            **{k: v for k, v in config.items() if k != 'model'}
        )
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")
        logger.info("ğŸ¯ Validation ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì¤‘...")
        best_model_path = run_dir / 'weights' / 'best.pt'
        if best_model_path.exists():
            trained_model = YOLO(str(best_model_path))
            create_validation_predictions(selected_images, trained_model, run_dir, data_config)
            logger.info("ğŸ² í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì¤‘...")
            create_test_predictions(trained_model, run_dir, data_config, num_samples=3)
        create_sample_summary(run_dir, selected_images)
        final_model_path = run_dir / 'weights' / 'best.pt'
        if final_model_path.exists():
            logger.info(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {final_model_path}")
            if fruit_name:
                best_model_copy = run_dir / 'weights' / f'best_{fruit_name}.pt'
                shutil.copy2(final_model_path, best_model_copy)
                logger.info(f"ê³¼ì‹¤ëª… í¬í•¨ ëª¨ë¸: {best_model_copy}")
        results_png = run_dir / 'results.png'
        if results_png.exists():
            logger.info(f"í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„: {results_png}")
        confusion_matrix_png = run_dir / 'confusion_matrix.png'
        if confusion_matrix_png.exists():
            logger.info(f"Confusion Matrix: {confusion_matrix_png}")
        samples_dir = run_dir / 'samples'
        if samples_dir.exists():
            logger.info(f"ğŸ“¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ì  ê²°ê³¼: {samples_dir}")
            logger.info("   â”œâ”€â”€ 01_original/     - ì›ë³¸ ì´ë¯¸ì§€ 3ì¥")
            logger.info("   â”œâ”€â”€ 02_augmented/    - ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€")
            logger.info("   â”œâ”€â”€ 03_validation/   - í•™ìŠµ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ (í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ bbox)")
            logger.info("   â”œâ”€â”€ 04_test_results/ - í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼ (í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ bbox)")
            logger.info("   â””â”€â”€ sample_summary.txt - ìš”ì•½ ì •ë³´")
            logger.info("   ìƒ‰ìƒ: ë¹¨ê°•(ripened), ì—°ë‘(ripening), íŒŒë‘(unripened)")
        return run_dir
    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def _normalize_device_arg(raw):
    """
    CLI --device ì¸ìë¥¼ Ultralyticsê°€ ë°›ëŠ” ìœ íš¨ ë¬¸ìì—´ë¡œ ì •ê·œí™”.
    - 'cpu' -> 'cpu'
    - 'auto' -> (GPU ìˆìœ¼ë©´ '0', ì—†ìœ¼ë©´ 'cpu')
    - '0' / '1' / '0,1' ë“± -> ê·¸ëŒ€ë¡œ
    - 0 / 1 (ì •ìˆ˜) -> '0', '1'
    """
    if isinstance(raw, int):
        return str(raw)
    s = str(raw).strip()
    if s.lower() == 'cpu':
        return 'cpu'
    if s.lower() == 'auto':
        return '0' if torch.cuda.is_available() else 'cpu'
    # ì½¤ë§ˆ êµ¬ë¶„ ë©€í‹°-GPUë„ ê·¸ëŒ€ë¡œ í—ˆìš©
    return s

def main():
    parser = argparse.ArgumentParser(description='YOLOv8 ê³¼ì‹¤ ì„±ìˆ™ë„ ê²€ì¶œ ëª¨ë¸ í•™ìŠµ (Detection ìœ íš¨ ì¸ì + ìƒ˜í”Œ ì¶”ì )')
    # í•„ìˆ˜
    parser.add_argument('--data', required=True, help='data.yaml íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output_dir', required=True, help='í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ')
    # ì„ íƒ
    parser.add_argument('--fruit', type=str, help='ê³¼ì‹¤ëª…(ì„ íƒ) - ê²°ê³¼ íŒŒì¼ëª…ì— ì¶”ê°€')
    parser.add_argument('--model_size', default='s', choices=['n','s','m','l','x'], help='ëª¨ë¸ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--imgsz', type=int, default=1080)
    parser.add_argument('--optimizer', default='SGD', choices=['SGD', 'Adam', 'AdamW'], help='Optimizer')
    parser.add_argument('--lr0', type=float, default=0.01)
    parser.add_argument('--device', default='auto', help="ë””ë°”ì´ìŠ¤ ('cpu', 'auto', '0', '0,1' ë“±)")
    parser.add_argument('--workers', type=int, default=8)
    parser.add_argument('--seed', type=int, default=42)
    # ---- Detection Augmentations ----
    parser.add_argument('--mosaic', type=float, default=1.0)
    parser.add_argument('--mixup', type=float, default=0.0)
    parser.add_argument('--copy_paste', type=float, default=0.0)
    parser.add_argument('--hsv_h', type=float, default=0.015)
    parser.add_argument('--hsv_s', type=float, default=0.7)
    parser.add_argument('--hsv_v', type=float, default=0.4)
    parser.add_argument('--fliplr', type=float, default=0.5)
    parser.add_argument('--flipud', type=float, default=0.0)
    parser.add_argument('--degrees', type=float, default=0.0)
    parser.add_argument('--translate', type=float, default=0.1)
    parser.add_argument('--scale', type=float, default=0.5)
    parser.add_argument('--shear', type=float, default=0.0)
    parser.add_argument('--perspective', type=float, default=0.0)
    parser.add_argument('--close_mosaic', type=int, default=10)
    # ---- ê¸°íƒ€ ----
    parser.add_argument('--freeze', type=int, default=0)
    parser.add_argument('--cos_lr', action='store_true', help='Cosine LR ì‚¬ìš©')

    args = parser.parse_args()

    # ì¬í˜„ì„±
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)

    # CUDA_VISIBLE_DEVICES ì„¤ì • (ì„ íƒì ): ìˆ«ì/ëª©ë¡ì¼ ë•Œë§Œ ì„¤ì •
    device_norm = _normalize_device_arg(args.device)
    if device_norm not in ('cpu',) and device_norm.lower() != 'cpu':
        # '0,1' ê°™ì€ í˜•ì‹ë§Œ í™˜ê²½ë³€ìˆ˜ë¡œ ë°˜ì˜
        os.environ["CUDA_VISIBLE_DEVICES"] = device_norm

    logger = setup_logging(args.output_dir, args.fruit)

    try:
        _ = verify_gpu_availability()

        training_config = create_training_config(
            model_size=args.model_size,
            epochs=args.epochs,
            batch_size=args.batch_size,
            imgsz=args.imgsz,
            optimizer=args.optimizer,
            lr0=args.lr0,
            workers=args.workers,
            seed=args.seed,
            mosaic=args.mosaic,
            mixup=args.mixup,
            copy_paste=args.copy_paste,
            hsv_h=args.hsv_h, hsv_s=args.hsv_s, hsv_v=args.hsv_v,
            fliplr=args.fliplr, flipud=args.flipud,
            degrees=args.degrees, translate=args.translate, scale=args.scale,
            shear=args.shear, perspective=args.perspective,
            close_mosaic=args.close_mosaic,
            freeze=args.freeze,
            cos_lr=args.cos_lr,
            device=device_norm  # â† ì—¬ê¸°ì„œ ìœ íš¨í•œ device ë¬¸ìì—´ ì „ë‹¬
        )

        logger.info("=== í•™ìŠµ ì„¤ì • ìš”ì•½ ===")
        for k, v in training_config.items():
            logger.info(f"{k}: {v}")

        run_dir = train_yolov8(args.data, args.output_dir, training_config, args.fruit)

        success_msg = f"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ê²°ê³¼ëŠ” ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {run_dir}"
        if args.fruit:
            success_msg += f"\nğŸ ê³¼ì‹¤: {args.fruit}"
        success_msg += f"\nğŸ“¸ ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶”ì  ê²°ê³¼: {run_dir / 'samples'}"
        success_msg += f"\nğŸ¨ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ: ë¹¨ê°•(ripened), ì—°ë‘(ripening), íŒŒë‘(unripened)"
        logger.info(success_msg)

    except Exception as e:
        logger.error(f"ğŸ’¥ í•™ìŠµ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()

