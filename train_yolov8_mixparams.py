#!/usr/bin/env python3
"""
YOLOv8ë¥¼ í™œìš©í•œ ê³¼ì‹¤ Detection ëª¨ë¸ í•™ìŠµ (+ ê°•í™”ëœ Augmentations)
- ë‚´ì¥: mosaic, mixup, copy_paste, HSV jitter
- ì»¤ìŠ¤í…€: CLAHE, gamma/contrast ê°•í™” (ì½œë°±ìœ¼ë¡œ ë°°ì¹˜ ì „ì²˜ë¦¬ì—ì„œ ì ìš©)
"""

import os
import yaml
import torch
from pathlib import Path
from ultralytics import YOLO
import argparse
import logging
from datetime import datetime
import shutil
import random
import numpy as np
import cv2

# =========================
# ë¡œê¹…
# =========================
def setup_logging(log_dir, fruit_name=None):
    log_dir = Path(log_dir)
    log_dir.mkdir(parents=True, exist_ok=True)
    fruit_suffix = f"_{fruit_name}" if fruit_name else ""
    log_file = log_dir / f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}{fruit_suffix}.log"
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[logging.FileHandler(log_file), logging.StreamHandler()]
    )
    logger = logging.getLogger(__name__)
    if fruit_name:
        logger.info(f"ğŸ ê³¼ì‹¤ ì¢…ë¥˜: {fruit_name}")
    return logger

# =========================
# GPU ì²´í¬
# =========================
def verify_gpu_availability():
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_device)
        print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_count}ê°œ GPU ê°ì§€")
        print(f"í˜„ì¬ GPU: {gpu_name}")
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        total_memory = torch.cuda.get_device_properties(current_device).total_memory
        print(f"GPU ë©”ëª¨ë¦¬: {total_memory / 1024**3:.1f}GB")
        return True
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í•™ìŠµí•˜ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.")
        return False

# =========================
# data.yaml ê²€ì¦
# =========================
def load_and_verify_config(data_yaml_path):
    data_yaml_path = Path(data_yaml_path)
    if not data_yaml_path.exists():
        raise FileNotFoundError(f"data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_yaml_path}")
    with open(data_yaml_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    required_keys = ['path', 'train', 'val', 'nc', 'names']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"data.yamlì— í•„ìˆ˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {key}")
    base_path = Path(config['path'])
    for split in ['train', 'val']:
        if split in config:
            split_path = base_path / config[split]
            if not split_path.exists():
                raise FileNotFoundError(f"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {split_path}")
    if len(config['names']) != config['nc']:
        raise ValueError(f"í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜: nc={config['nc']}, names ê¸¸ì´={len(config['names'])}")
    print("âœ… ë°ì´í„° ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    print(f"   - í´ë˜ìŠ¤ ìˆ˜: {config['nc']}")
    print(f"   - í´ë˜ìŠ¤: {config['names']}")
    print(f"   - ë°ì´í„° ê²½ë¡œ: {config['path']}")
    return config

# =========================
# ì»¤ìŠ¤í…€ ì½œë°±: CLAHE + Gamma/Contrast
# =========================
def _apply_clahe_gamma_contrast(img_np_uint8, use_clahe=True, clahe_clip=2.0, clahe_grid=8,
                                gamma_range=(0.8, 1.2), contrast_range=(0.9, 1.1),
                                p_clahe=0.7, p_gamma=0.8, p_contrast=0.8, rng=None):
    """img_np_uint8: BGR(H,W,3), np.uint8"""
    if rng is None:
        rng = random

    out = img_np_uint8

    # CLAHE (V ì±„ë„ì— ì ìš©)
    if use_clahe and rng.random() < p_clahe:
        hsv = cv2.cvtColor(out, cv2.COLOR_BGR2HSV)
        v = hsv[:, :, 2]
        clahe = cv2.createCLAHE(clipLimit=float(clahe_clip), tileGridSize=(clahe_grid, clahe_grid))
        v = clahe.apply(v)
        hsv[:, :, 2] = v
        out = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

    # Gamma
    if rng.random() < p_gamma:
        g = rng.uniform(gamma_range[0], gamma_range[1])
        # gamma ë³´ì •: out = 255 * (img/255) ** g
        table = np.array([((i / 255.0) ** g) * 255.0 for i in range(256)]).astype(np.uint8)
        out = cv2.LUT(out, table)

    # Contrast (ê°„ë‹¨í•œ gain, center 128 ê¸°ì¤€)
    if rng.random() < p_contrast:
        c = rng.uniform(contrast_range[0], contrast_range[1])
        out = cv2.addWeighted(out, c, np.zeros_like(out), 0, 128*(1-c))

    return out

def build_preprocess_callback(
    enable_clahe_gamma=True,
    clahe_clip=2.0,
    clahe_grid=8,
    gamma_low=0.8,
    gamma_high=1.2,
    contrast_low=0.9,
    contrast_high=1.1,
    p_clahe=0.7,
    p_gamma=0.8,
    p_contrast=0.8,
    seed=42
):
    rng = random.Random(seed)

    def on_preprocess_batch(trainer):
        # trainer.batch: dict with 'img' (torch.FloatTensor, shape [B,3,H,W], 0-1)
        batch = trainer.batch
        if batch is None or 'img' not in batch:
            return
        if not enable_clahe_gamma:
            return

        imgs = batch['img']  # torch.FloatTensor
        if not isinstance(imgs, torch.Tensor):
            return

        imgs_np = imgs.detach().cpu().numpy()  # [B,3,H,W], 0~1 float
        B, C, H, W = imgs_np.shape
        for i in range(B):
            # to uint8 BGR
            img_chw = imgs_np[i]
            img_hwc = np.transpose(img_chw, (1, 2, 0))  # HWC, RGB
            img_u8 = np.clip(img_hwc * 255.0, 0, 255).astype(np.uint8)
            img_bgr = cv2.cvtColor(img_u8, cv2.COLOR_RGB2BGR)

            # apply
            img_bgr = _apply_clahe_gamma_contrast(
                img_bgr,
                use_clahe=True,
                clahe_clip=clahe_clip,
                clahe_grid=clahe_grid,
                gamma_range=(gamma_low, gamma_high),
                contrast_range=(contrast_low, contrast_high),
                p_clahe=p_clahe, p_gamma=p_gamma, p_contrast=p_contrast,
                rng=rng
            )

            # back to tensor [0,1], RGB
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            img_rgb = img_rgb.astype(np.float32) / 255.0
            imgs_np[i] = np.transpose(img_rgb, (2, 0, 1))

        # ë®ì–´ì“°ê¸°
        batch['img'] = torch.from_numpy(imgs_np).to(imgs.device)

    return on_preprocess_batch

# =========================
# í•™ìŠµ ì„¤ì •
# =========================
def create_training_config(
    model_size='s',
    epochs=10,
    batch_size=32,
    imgsz=1080,
    optimizer='SGD',
    # ë‚´ì¥ Augs (ìš”ì²­ ë°˜ì˜)
    mosaic=1.0,          # 0.0~1.0 (í™•ë¥ /ê°•ë„)
    mixup=0.7,           # ì´ë¯¸ ì¸ìë¡œ ìˆë˜ ê°’ ìœ ì§€/ë…¸ì¶œ
    copy_paste=0.5,      # 0~1
    hsv_h=0.015,         # hue jitter
    hsv_s=0.7,           # saturation jitter (ì±„ë„)
    hsv_v=0.7,           # value jitter (ëª…ë„)
    fliplr=0.5,
    flipud=0.7,
    degrees=90.0,
    translate=0.1,
    scale=0.5,
    shear=5.0,
    perspective=0.0005,
    # ì˜µí‹°ë§ˆì´ì € & loss
    lr0=1E-2,
    lrf=0.01,
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3,
    warmup_momentum=0.8,
    warmup_bias_lr=0.1,
    box_gain=7.5,
    cls_gain=0.5,
    dfl_gain=1.5,
    save_period=-1,
    workers=8,
    **kwargs
):
    config = {
        'model': f'yolov8{model_size}.pt',
        'epochs': epochs,
        'batch': batch_size,
        'imgsz': imgsz,
        'device': 'auto',
        'optimizer': optimizer,
        'lr0': lr0,
        'lrf': lrf,
        'momentum': momentum,
        'weight_decay': weight_decay,
        'warmup_epochs': warmup_epochs,
        'warmup_momentum': warmup_momentum,
        'warmup_bias_lr': warmup_bias_lr,
        'box': box_gain,
        'cls': cls_gain,
        'dfl': dfl_gain,

        # ===== ë‚´ì¥ ë°ì´í„° ì¦ê°• (YOLOv8 í•˜ì´í¼íŒŒë¼ë¯¸í„°) =====
        'mosaic': mosaic,
        'mixup': mixup,
        'copy_paste': copy_paste,
        'hsv_h': hsv_h,
        'hsv_s': hsv_s,
        'hsv_v': hsv_v,
        'fliplr': fliplr,
        'flipud': flipud,
        'degrees': degrees,
        'translate': translate,
        'scale': scale,
        'shear': shear,
        'perspective': perspective,

        'workers': workers,
        'save': True,
        'save_period': save_period,
        'val': True,
        'verbose': True,
        'seed': 42,
        'exist_ok': True,
    }
    config.update(kwargs)
    return config

# =========================
# í•™ìŠµ ì‹¤í–‰
# =========================
def train_yolov8(data_yaml_path, output_dir, config, fruit_name=None,
                 enable_clahe_gamma=True,
                 clahe_clip=2.0, clahe_grid=8,
                 gamma_low=0.8, gamma_high=1.2,
                 contrast_low=0.9, contrast_high=1.1,
                 p_clahe=0.7, p_gamma=0.8, p_contrast=0.8,
                 seed=42):
    logger = logging.getLogger(__name__)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    fruit_suffix = f"_{fruit_name}" if fruit_name else ""
    run_name = f"train_{timestamp}{fruit_suffix}"
    run_dir = output_dir / run_name

    logger.info(f"í•™ìŠµ ì‹œì‘: {run_name}")
    logger.info(f"ì¶œë ¥ ê²½ë¡œ: {run_dir}")

    try:
        model_name = config['model']
        logger.info(f"ëª¨ë¸ ë¡œë“œ: {model_name}")
        model = YOLO(model_name)

        logger.info("ëª¨ë¸ êµ¬ì¡°:")
        logger.info(f"  - Parameters: {sum(p.numel() for p in model.model.parameters()):,}")
        logger.info(f"  - Trainable params: {sum(p.numel() for p in model.model.parameters() if p.requires_grad):,}")

        # ì„¤ì • ì €ì¥
        config_filename = f"training_config{fruit_suffix}.yaml"
        config_save_path = run_dir / config_filename
        run_dir.mkdir(parents=True, exist_ok=True)
        config_to_save = config.copy()
        if fruit_name:
            config_to_save['fruit_name'] = fruit_name
        with open(config_save_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_to_save, f, default_flow_style=False, allow_unicode=True)
        logger.info(f"í•™ìŠµ ì„¤ì • ì €ì¥: {config_save_path}")

        # ===== ì»¤ìŠ¤í…€ ì½œë°± ë“±ë¡ (CLAHE + gamma/contrast) =====
        if enable_clahe_gamma:
            cb = build_preprocess_callback(
                enable_clahe_gamma=True,
                clahe_clip=clahe_clip, clahe_grid=clahe_grid,
                gamma_low=gamma_low, gamma_high=gamma_high,
                contrast_low=contrast_low, contrast_high=contrast_high,
                p_clahe=p_clahe, p_gamma=p_gamma, p_contrast=p_contrast,
                seed=seed
            )
            # YOLOv8 ì½œë°± í›…: on_preprocess_batch
            model.add_callback("on_preprocess_batch", cb)
            logger.info("ì»¤ìŠ¤í…€ Augmentation ì½œë°± ë“±ë¡: CLAHE + gamma/contrast")

        # ===== í•™ìŠµ =====
        logger.info("í•™ìŠµ ì‹¤í–‰ ì¤‘...")
        results = model.train(
            data=data_yaml_path,
            project=str(output_dir),
            name=run_name,
            **{k: v for k, v in config.items() if k != 'model'}
        )
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")

        # ê²°ê³¼ ìš”ì•½
        final_model_path = run_dir / 'weights' / 'best.pt'
        if final_model_path.exists():
            logger.info(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {final_model_path}")
            if fruit_name:
                best_model_copy = run_dir / 'weights' / f'best_{fruit_name}.pt'
                shutil.copy2(final_model_path, best_model_copy)
                logger.info(f"ê³¼ì‹¤ëª… í¬í•¨ ëª¨ë¸: {best_model_copy}")

        results_png = run_dir / 'results.png'
        if results_png.exists():
            logger.info(f"í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„: {results_png}")
            if fruit_name:
                results_copy = run_dir / f'results_{fruit_name}.png'
                shutil.copy2(results_png, results_copy)
                logger.info(f"ê³¼ì‹¤ëª… í¬í•¨ ê²°ê³¼ ê·¸ë˜í”„: {results_copy}")

        confusion_matrix_png = run_dir / 'confusion_matrix.png'
        if confusion_matrix_png.exists() and fruit_name:
            confusion_copy = run_dir / f'confusion_matrix_{fruit_name}.png'
            shutil.copy2(confusion_matrix_png, confusion_copy)
            logger.info(f"ê³¼ì‹¤ëª… í¬í•¨ Confusion Matrix: {confusion_copy}")

        return run_dir

    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

# =========================
# CLI
# =========================
def main():
    parser = argparse.ArgumentParser(description='YOLOv8 ê³¼ì‹¤ ì„±ìˆ™ë„ ê²€ì¶œ ëª¨ë¸ í•™ìŠµ (+ê°•í™” Augmentations)')

    # í•„ìˆ˜
    parser.add_argument('--data', required=True, help='data.yaml íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output_dir', required=True, help='í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ')

    # ì„ íƒ
    parser.add_argument('--fruit', type=str, help='ê³¼ì‹¤ëª…(ì„ íƒ) - ê²°ê³¼ íŒŒì¼ëª…ì— ì¶”ê°€')
    parser.add_argument('--model_size', default='s', choices=['n','s','m','l','x'], help='ëª¨ë¸ í¬ê¸°')
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--imgsz', type=int, default=1080)
    parser.add_argument('--lr0', type=float, default=1e-2)
    parser.add_argument('--device', default='auto', help='ë””ë°”ì´ìŠ¤ (auto, 0, 1, cpu)')
    parser.add_argument('--workers', type=int, default=8)
    parser.add_argument('--seed', type=int, default=42)

    # ===== ë‚´ì¥ Augmentation íŒŒë¼ë¯¸í„° =====
    parser.add_argument('--mosaic', type=float, default=1.0)
    parser.add_argument('--mixup', type=float, default=0.7)
    parser.add_argument('--copy_paste', type=float, default=0.5)
    parser.add_argument('--hsv_h', type=float, default=0.015)
    parser.add_argument('--hsv_s', type=float, default=0.7)
    parser.add_argument('--hsv_v', type=float, default=0.7)
    parser.add_argument('--fliplr', type=float, default=0.5)
    parser.add_argument('--flipud', type=float, default=0.7)
    parser.add_argument('--degrees', type=float, default=90.0)
    parser.add_argument('--translate', type=float, default=0.1)
    parser.add_argument('--scale', type=float, default=0.5)
    parser.add_argument('--shear', type=float, default=5.0)
    parser.add_argument('--perspective', type=float, default=0.0005)

    # ===== ì»¤ìŠ¤í…€(CLAHE + gamma/contrast) íŒŒë¼ë¯¸í„° =====
    parser.add_argument('--enable_clahe_gamma', action='store_true', help='CLAHE & gamma/contrast ì½œë°± í™œì„±í™”')
    parser.add_argument('--clahe_clip', type=float, default=2.0)
    parser.add_argument('--clahe_grid', type=int, default=8)
    parser.add_argument('--gamma_low', type=float, default=0.8)
    parser.add_argument('--gamma_high', type=float, default=1.2)
    parser.add_argument('--contrast_low', type=float, default=0.9)
    parser.add_argument('--contrast_high', type=float, default=1.1)
    parser.add_argument('--p_clahe', type=float, default=0.7)
    parser.add_argument('--p_gamma', type=float, default=0.8)
    parser.add_argument('--p_contrast', type=float, default=0.8)

    args = parser.parse_args()

    if args.device not in ("auto", "cpu"):
        os.environ["CUDA_VISIBLE_DEVICES"] = str(args.device)

    logger = setup_logging(args.output_dir, args.fruit)

    try:
        _ = verify_gpu_availability()
        _ = load_and_verify_config(args.data)

        training_config = create_training_config(
            model_size=args.model_size,
            epochs=args.epochs,
            batch_size=args.batch_size,
            imgsz=args.imgsz,
            lr0=args.lr0,
            workers=args.workers,
            device=args.device,
            seed=args.seed,
            # ë‚´ì¥ augs
            mosaic=args.mosaic,
            mixup=args.mixup,
            copy_paste=args.copy_paste,
            hsv_h=args.hsv_h,
            hsv_s=args.hsv_s,
            hsv_v=args.hsv_v,
            fliplr=args.fliplr,
            flipud=args.flipud,
            degrees=args.degrees,
            translate=args.translate,
            scale=args.scale,
            shear=args.shear,
            perspective=args.perspective,
        )

        logger.info("=== í•™ìŠµ ì„¤ì • ìš”ì•½ ===")
        for k, v in training_config.items():
            logger.info(f"{k}: {v}")

        run_dir = train_yolov8(
            args.data, args.output_dir, training_config, args.fruit,
            enable_clahe_gamma=args.enable_clahe_gamma,
            clahe_clip=args.clahe_clip, clahe_grid=args.clahe_grid,
            gamma_low=args.gamma_low, gamma_high=args.gamma_high,
            contrast_low=args.contrast_low, contrast_high=args.contrast_high,
            p_clahe=args.p_clahe, p_gamma=args.p_gamma, p_contrast=args.p_contrast,
            seed=args.seed
        )

        success_msg = f"ğŸ‰ í•™ìŠµ ì™„ë£Œ! ê²°ê³¼ëŠ” ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {run_dir}"
        if args.fruit:
            success_msg += f"\nğŸ ê³¼ì‹¤: {args.fruit}"
        logger.info(success_msg)

    except Exception as e:
        logger.error(f"ğŸ’¥ í•™ìŠµ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()
